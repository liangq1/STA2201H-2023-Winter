---
title: "Lab 6"
author: "Qiaoyu Liang"
date: "2023-02-17"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


# Introduction

This lab will be looking at trying to replicate some of the visualizations in the lecture notes, involving prior and posterior predictive checks, and LOO model comparisons. 

The dataset is a 0.1% of all births in the US in 2017. I've pulled out a few different variables, but as in the lecture, we'll just focus on birth weight and gestational age. 

# The data

Read it in, along with all our packages. 

```{r}
library(tidyverse)
library(here)
# for bayes stuff
library(rstan)
library(bayesplot) 
library(loo) 
library(tidybayes) 
library(fdrtool)
library(kableExtra)
ds <- read_rds("births_2017_sample.RDS")
head(ds)
```

Brief overview of variables:

- `mager` mum's age
- `mracehisp` mum's race/ethnicity see here for codes: https://data.nber.org/natality/2017/natl2017.pdf page 15
- `meduc` mum's education see here for codes: https://data.nber.org/natality/2017/natl2017.pdf page 16
- `bmi` mum's bmi 
- `sex` baby's sex
- `combgest` gestational age in weeks
- `dbwt` birth weight in kg
- `ilive` alive at time of report y/n/ unsure

I'm going to rename some variables, remove any observations with missing gestational age or birth weight, restrict just to babies that were alive, and make a preterm variable. 

```{r}
ds <- ds %>% 
  rename(birthweight = dbwt, gest = combgest) %>% 
  mutate(preterm = ifelse(gest<32, "Y", "N")) %>% 
  filter(ilive=="Y",gest< 99, birthweight<9.999)
```


## Question 1

Use plots or tables to show three interesting observations about the data. Remember:

- Explain what your graph/ tables show
- Choose a graph type that's appropriate to the data type
- If you use `geom_smooth`, please also plot the underlying data

Feel free to replicate one of the scatter plots in the lectures as one of the interesting observations, as those form the basis of our models. 


### Graph 1

```{r}
ds %>% ggplot(aes(log(gest), log(birthweight), color = sex)) +
       geom_point() + geom_smooth(method = "lm", se = TRUE) +
       scale_color_brewer(palette = "Set1") +
       labs(title="Birthweight vs Gestational age ",
            x = "log(gest)", 
            y = "log(birthweight)")
```

As the scatterplot shows, there seems a positive linear relationship between log gestational age and log birthweight no matter whether the baby is male or female.


### Graph 2

```{r}
ds %>% ggplot(aes(log(gest), log(birthweight), color = preterm)) +
  ylim(-1,2) + geom_point() + geom_smooth(method = "lm", se = TRUE) +
  scale_color_brewer(palette = "Set1") +
  labs(title="Birthweight vs Gestational age ",
       x ="log(gest)", 
       y = "log(birthweight)")
```

As the scatterplot shows, there is a positive linear relationship between the log birthweight and log gestational age, but the slope of the linear relationship differs based on whether the baby was born preterm or not.

### Graph 3

```{r}
ggplot(data = ds, aes(x = sex, y = birthweight, color = sex)) + 
  geom_boxplot()
```

As the boxplot shows, it seems that male babies' weight is slightly larger than female ones on average.

# The model

As in lecture, we will look at two candidate models 

Model 1 has log birth weight as a function of log gestational age

$$
\log(y_i) \sim N(\beta_1 + \beta_2\log(x_i), \sigma^2)
$$

Model 2 has an interaction term between gestation and prematurity

$$
\log(y_i) \sim N(\beta_1 + \beta_2\log(x_i) + \beta_2 z_i + \beta_3\log(x_i) z_i, \sigma^2)
$$

- $y_i$ is weight in kg
- $x_i$ is gestational age in weeks, CENTERED AND STANDARDIZED
- $z_i$ is preterm (0 or 1, if gestational age is less than 32 weeks)


# Prior predictive checks

Let's put some weakly informative priors on all parameters i.e. for the $\beta$s

$$
\beta \sim N(0, 1)
$$

and for $\sigma$

$$
\sigma \sim N^+(0,1)
$$
where the plus means positive values only i.e. Half Normal. 

Let's check to see what the resulting distribution of birth weights look like given Model 1 and the priors specified above, assuming we had no data on birth weight (but observations of gestational age).

## Question 2

For Model 1, simulate values of $\beta$s and $\sigma$ based on the priors above. Do 1000 simulations. Use these values to simulate (log) birth weights from the likelihood specified in Model 1, based on the set of observed gestational weights. **Remember the gestational weights should be centered and standardized**. 

- Plot the resulting distribution of simulated (log) birth weights. 
- Plot ten simulations of (log) birthweights against gestational age. 

### Plot the resulting distribution of simulated (log) birth weights

```{r}
set.seed(2201)
nsims <- 1000
beta0 <- rnorm(nsims, 0, 1)
beta1 <- rnorm(nsims, 0, 1)
sigma <- abs(rnorm(nsims, 0, 1))

gest_standard <- tibble(log_gest_c = (log(ds$gest) - mean(log(ds$gest)))/sd(log(ds$gest)))

for(i in 1:nsims){
  this_mu <- beta0[i] + beta1[i] * gest_standard$log_gest_c 
  gest_standard[paste0(i)] <- this_mu + rnorm(nrow(gest_standard), 0, sigma[i])
}

dsl1000 <- gest_standard %>%
pivot_longer(`1`:`1000`, names_to = "sim", values_to = "sim_weight")

  
dsl1000 %>% 
  ggplot(aes(sim_weight)) + geom_histogram(aes(y = ..density..), 
                                           bins = 20, fill = "turquoise", 
                                           color = "black") + 
  theme_bw(base_size = 14)
```

### Plot ten simulations of (log) birthweights against gestational age

```{r}
dsl10 <- gest_standard %>% 
  pivot_longer(`1`:`10`, names_to = "sim", values_to = "sim_weight")
dsl10 %>%
  ggplot(aes(x=log_gest_c, y=sim_weight, color=sim)) + geom_point() +
  geom_smooth(method = "lm")
```

# Run the model

Now we're going to run Model 1 in Stan. The stan code is in the `code/models` folder. 

First, get our data into right form for input into stan. 

```{r}
ds$log_weight <- log(ds$birthweight)
ds$log_gest_c <- (log(ds$gest) - mean(log(ds$gest)))/sd(log(ds$gest))

# put into a list
stan_data <- list(N = nrow(ds),
                  log_weight = ds$log_weight,
                  log_gest = ds$log_gest_c)
```

Now fit the model

```{r, results='hide'}
mod1 <- stan(data = stan_data, 
             file = "simple_weight.stan",
             iter = 500,
             seed = 243)
```


```{r}
summary(mod1)$summary[c("beta[1]", "beta[2]", "sigma"),]
```

## Question 3

Based on model 1, give an estimate of the expected birthweight of a baby who was born at a gestational age of 37 weeks. 

```{r}
gest37 <- (log(37) - mean(log(ds$gest))) / sd(log(ds$gest))
beta0Q3 <-  summary(mod1)$summary[c("beta[1]", "beta[2]", "sigma"),][1,1]
beta1Q3 <-  summary(mod1)$summary[c("beta[1]", "beta[2]", "sigma"),][2,1]
E_birthweight <- exp(beta0Q3 + beta1Q3 * gest37)
E_birthweight
```

An estimate of the expected birthweight of a baby who was born at a gestational age of 37 weeks is 2.935874.

## Question 4

Write a stan model to run Model 2, and run it. 

```{r, results='hide'}
preterm <- ifelse(ds$preterm=="Y", 1, 0)
stan_data <- list(N = nrow(ds),
                  log_weight = ds$log_weight,
                  log_gest = ds$log_gest_c,
                  preterm = preterm)

mod2_myself <- stan(data = stan_data, 
             file = "simple_weight_model2.stan",
             iter = 500,
             seed = 243)
```


## Question 5

For reference I have uploaded some model 2 results. Check your results are similar. 

```{r}
load("mod2.Rda")
summary(mod2)$summary[c(paste0("beta[", 1:4, "]"), "sigma"),]
```


```{r}
summary(mod2_myself)$summary[c(paste0("beta[", 1:4, "]"), "sigma"),]
```

From the summary above, we find that results are similar but it seems the beta2 and beta3 are flipped between the two models.

# PPCs

Now we've run two candidate models let's do some posterior predictive checks. The `bayesplot` package has a lot of inbuilt graphing functions to do this. For example, let's plot the distribution of our data (y) against 100 different datasets drawn from the posterior predictive distribution:

```{r}
set.seed(1856)
y <- ds$log_weight
yrep1 <- extract(mod1)[["log_weight_rep"]]
yrep2 <- extract(mod2)[["log_weight_rep"]] 
dim(yrep1)
samp100 <- sample(nrow(yrep1), 100)
ppc_dens_overlay(y, yrep1[samp100, ])  + ggtitle("Distribution of observed versus predicted birthweights for model 1")
```

## Question 6

Make a similar plot to the one above but for model 2, and **not** using the bayes plot in built function (i.e. do it yourself just with `geom_density`)

Notice the model 2 being used is mod2_myself.

```{r}
set.seed(2201)
y <- ds$log_weight
yrep2 <- extract(mod2_myself)[["log_weight_rep"]] 
samp100_2 <- sample(nrow(yrep2), 100)
rownames(yrep2) <- 1:nrow(yrep2)
dr <- as_tibble(t(yrep2))
dr <- dr %>% bind_cols(i = 1:nrow(ds), log_weight_obs = log(ds$birthweight))

dr <- dr %>% 
  pivot_longer(-(i:log_weight_obs), names_to = "sim", values_to ="y_rep")

dr %>% 
  filter(sim %in% samp100_2) %>% 
  ggplot(aes(y_rep, group = sim)) + 
  geom_density(alpha = 0.2, aes(color = "y_rep")) + 
  geom_density(data = ds %>% mutate(sim = 1), 
               aes(x = log(birthweight), col = "y")) + 
  scale_color_manual(name = "", 
                     values = c("y" = "darkblue", 
                                "y_rep" = "lightblue")) + 
  labs(x = "y_rep", y="Density", 
       title = "Distribution of observed and replicated birthweights for model 2")
```


## Test statistics

We can also look at some summary statistics in the PPD versus the data, again either using `bayesplot` -- the function of interest is `ppc_stat` or `ppc_stat_grouped` -- or just doing it ourselves using ggplot. 

E.g. medians by prematurity for Model 1

```{r}
ppc_stat_grouped(ds$log_weight, yrep1, group = ds$preterm, stat = 'median')
```

## Question 7

Use a test statistic of the proportion of births under 2.5kg. Calculate the test statistic for the data, and the posterior predictive samples for both models, and plot the comparison (one plot per model). 

```{r}
# The test statistics for the data
y <- ds$log_weight
t_y <- mean(y<=log(2.5))
t_y
```


```{r}
# Plot for Model 1
t_y_rep <- sapply(1:nrow(yrep1), function(i) mean(yrep1[i,] <= log(2.5)))
t_y_rep_2 <- sapply(1:nrow(yrep2), function(i) mean(yrep2[i,] <= log(2.5)))

ggplot(data = as_tibble(t_y_rep), aes(value)) + 
    geom_histogram(aes(fill = "replicated")) + 
    geom_vline(aes(xintercept = t_y, color = "observed"), lwd = 1.5) + 
  ggtitle("Model 1: proportion of births less than 2.5kg") + 
  theme_bw(base_size = 12) + 
  scale_color_manual(name = "", 
                     values = c("observed" = "darkblue"))+
  scale_fill_manual(name = "", 
                     values = c("replicated" = "lightblue")) 
```


```{r}
# Plot for Model 2
ggplot(data = as_tibble(t_y_rep_2), aes(value)) + 
    geom_histogram(aes(fill = "replicated")) + 
    geom_vline(aes(xintercept = t_y, color = "observed"), lwd = 1.5) + 
  ggtitle("Model 2: proportion of births less than 2.5kg") + 
  theme_bw(base_size = 12) + 
  scale_color_manual(name = "", 
                     values = c("observed" = "darkblue"))+
  scale_fill_manual(name = "", 
                     values = c("replicated" = "lightblue")) 
```


# LOO

Finally let's calculate the LOO elpd for each model and compare. The first step of this is to get the point-wise log likelihood estimates from each model:

```{r}
loglik1 <- extract(mod1)[["log_lik"]]
loglik2 <- extract(mod2_myself)[["log_lik"]]
```


And then we can use these in the `loo` function to get estimates for the elpd. Note the `save_psis = TRUE` argument saves the calculation for each simulated draw, which is needed for the LOO-PIT calculation below. 

```{r}
loo1 <- loo(loglik1, save_psis = TRUE)
loo2 <- loo(loglik2, save_psis = TRUE)
```

Look at the output:


```{r}
loo1
loo2
```

Comparing the two models tells us Model 2 is better:

```{r}
loo_compare(loo1, loo2)
```

We can also compare the LOO-PIT of each of the models to standard uniforms. The both do pretty well. 

```{r}
ppc_loo_pit_overlay(yrep = yrep1, y = y, lw = weights(loo1$psis_object))
ppc_loo_pit_overlay(yrep = yrep2, y = y, lw = weights(loo2$psis_object))
```


## Bonus question (not required)

Create your own PIT histogram "from scratch" for Model 2.

```{r}
library(stringr)
library(dplyr)
library(tidyr)
library(ggplot2)

yrep2 <- t(yrep2)
yrep2_tibble <- yrep2 %>% as_tibble() 

result <- yrep2_tibble %>% 
  mutate(y = y, cbind_cols = 1:n()) %>% 
  pivot_longer(cols = -(y:cbind_cols), names_to = "sim", values_to = "yrep") %>% 
  mutate(sim = as.numeric(str_remove(sim, "V"))) %>% 
  mutate(count = yrep <= y) %>% 
  group_by(cbind_cols) %>% 
  summarize(PIT = mean(count)) 

ggplot(data = result, aes(x = PIT)) + 
  geom_histogram(aes(y = ..density..), bins = 20, fill = "lightblue", color = "black") +
  geom_density(color = "red", lwd = 1) +
  labs(x = "Proportion", y="Density", 
       title = "PIT for Model 2") + 
  geom_hline(yintercept = 1)
```


## Question 8

Based on the original dataset, choose one (or more) additional covariates to add to the linear regression model. Run the model in Stan, and compare with Model 2 above on at least 2 posterior predictive checks.

Since my EDA indicates there are some differences between baby boys and baby girls, I choose to add the variable “sex” into the linear regression model.

```{r}
ds$sex <- ifelse(ds$sex == "M", 1,0)
stan_data<- list(N = nrow(ds),
                 log_weight = ds$log_weight,
                 log_gest = ds$log_gest_c,
                 preterm = preterm,
                 sex = ds$sex)
# Fit Model3
mod3 <- stan(data = stan_data, 
             file = "simple_weight_model3.stan",
             iter = 500,
             seed = 243)
```

## Compare with Model 2 above on at least 2 posterior predictive checks.

### First check: The distribution of data (y) and 100 different datasets drawn from the posterior predictive distribution

```{r}
set.seed(2201)
y <- ds$log_weight
yrep2 <- extract(mod2_myself)[["log_weight_rep"]] 
samp100_2 <- sample(nrow(yrep2), 100)
yrep3 <- extract(mod3)[["log_weight_rep"]]
samp100_3 <- sample(nrow(yrep3), 100)

ppc_dens_overlay(y, yrep2[samp100_2, ])  + ggtitle("Observed and Simulated Birth Weight Distributions from model 2")
ppc_dens_overlay(y, yrep3[samp100_3, ])  + ggtitle("Observed and Simulated Birth Weight Distributions from model 3")
```

From the above two plots, there is not much difference between model 2 and model 3. 

### Second check: Test statistics: median

```{r}
ts1 <- ppc_stat(y, yrep2[samp100_2, ], stat = 'median') +
  ggtitle("Median Distribution across Simulated Datasets for Model 2")
ts2 <- ppc_stat(y, yrep3[samp100_3, ], stat = 'median') +
  ggtitle("Median Distribution across Simulated Datasets for Model 3")
ts1
ts2
```

The above two plots shows the distribution of the median across the 100 simulated datasets for model 2 and model 3. We find the simulated distribution of the median for model 2 is slightly closer to the value observed in the data. However, it is hard to say the difference is significant only based on the plots.


